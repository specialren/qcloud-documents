## 业务场景
腾讯优码从连接消费者到连接渠道终端，实现以货的数字化为基础的企业数字化升级，包含营销能力升级和动销能力升级。更多信息，请参见 [腾讯优码官网](https://uma.qq.com/)。

腾讯智慧零售优码业务最核心的数据为**存储零售商品二维码信息**，码数据存储问题是项目最核心的问题。码存储数据特点如下：
- 海量数据
  随着越来越多的商品使用腾讯优码业务，二维码数据开始呈现指数级增长。 
- 关联存储
  码与码之间存在1:1和1:N:N的关联关系，需要存储这种关系，并且提供相应的关联查询。 
- 多维度查询
  针对不同的应用场景需要提供不同维度的条件查询。 

## 方案分析
经过多方调研和排查之后，初步选取了以下存储方案。

### MySQL + ES 存储方案
此方案写操作直接作用于 MySQL，通过 canal + Kafka 的方式将数据变更同步到 ES，再根据不同的查询场景从 MySQL 或者 ES 查询数据。该方案可提供非常多的查询方式和不同的性能保障，可应对各种各样复杂的业务查询需求。 
![](https://qcloudimg.tencent-cloud.cn/raw/2d3214daaadf770d1ed747498b5c10f3.png)

### MongoDB 方案
MongoDB 具备 No Schema、高可用、分布式、数据压缩等多方面的优势，在提供分布式存储的前提下，同时能够提供大部分 MySQL 支持的查询方式。
在腾讯优码的应用场景下，基于 MongoDB 的存储架构，如下图所示 ，其并不需要 MySQL 冗余表或者 ES 来支持大部分的分布式查询。
![](https://qcloudimg.tencent-cloud.cn/raw/a0dda03553582943d10311f377a5dda7.png)

### 方案对比分析
从功能、性能、成本、可扩展性和可维护性等方面对比两个方案，如下表所示。MongoDB 不仅能完全满足业务需求，同时在性能、成本、可维护性等各方面都优于其它方案。腾讯优码最终选用的是 MongoDB 作为业务核心数据码的存储方案。 

| 对比项   | 指标要求                       | MySQL + ES                             | MongoDB                                                      |
| -------- | ------------------------------------ | ----------------------------------- | ------------------------------------------------------------ |
| 功能     |<li>分片键查询</li><li>非分片键查询</li><li>按索引聚合查询</li><li>父子关系查询判断</li> | <li>MySQL 需要辅助表来实现 C 端业务费非分片键查询</li><li>需要 ES 来实现 B 端不同维度查询</li><li>不支持父子码查询</li> | <li>一份数据满足不同维度查询</li><li>数据类型的多 Key 索引支持父子关系查询</li> |
| 性能     | 存储规格4核8GB           | <li>MySQL 读性能约 6000 QPS</li><li>ES 仅约 800 QPS</li> | 单分片读性能约 3万 QPS          |
| 成本     | 按容量50TB数据            | 磁盘容量需求为 MySQL 50TB，ES 60TB，总计110TB         | <li>自带数据压缩，无冗余存储<li>内存容量 MongoDB:MySQL:ES 约为1:3:6的比例</li><li>磁盘容量要求：16.67TB，其为 MySQL 磁盘消耗的三分之一</li> |
| 可扩展性 | <li>是否动态扩容</li><li>磁盘容量要求：16.67TB</li>   | <li>需要提前根据数量预分片</li><li>分片扩容难，需要业务手动 rehash 搬迁数据，并自己保证数据一致性与完整性</li> | <li>动态扩容，不存在容量上限</li><li>自动 rebalance 数据，保证各个分片负载均匀</li> |
| 可维护性 | <li>DBA （Database Administrator）维度</li><li>数据一致性</li><li>运维成本</li> | <li>DDL（Database Administrator）/DML（Database Administrator）执行非常耗时</li><li>数据有多个副本，需要复杂的架构和开发来维护数据一致性难</li><li>开发维护分库分表和数据同步的配置和实现，存在业务抖动风险，发布耗时且风险大</li> | <li>No Schema 无需频繁 DDL</li><li>一份数据满足多种业务需求，不需要维护数据一致性，大幅减少开发与运维难度</li> |

## 方案优化
鉴于零售优码对成本要求较高，数据量较大，读写流量要求不高，推荐选择 MongoDB 4核8GB低规格分片集群部署。针对零售业务场景，保证数据读写性能及可靠性，避免一些业务抖动风险，MongoDB 团队给出如下集群优化建议。

###  分片集群片键选择 + 预分片 
**片键选择**
零售优码数据查询都是通过码 ID 查询，因此，可选择码 ID 作为片键，以最大化保证查询性能。

**预分片**
索引查询可以通过同一个分片获取数据。为避免分片间数据不均衡引起的 moveChunk 操作，选择 hashed 分片方式，并提前进行预分片。MongoDB 默认支持 hashed 预分片，则预分片方式如下所示。
```
use db_code_xx  
sh.enableSharding("db_code_xx")  
//n 为实际分片数 
sh.shardCollection("db_code_xx.t_code_xx", {"id": "hashed"}, false,{numInitialChunks:8192*n})
```

### 低峰期 balance 窗口设置
MongoDB 4核8GB低规格，当分片间 chunks 数据不均衡时，会触发自动 balance 均衡，moveChunk 不停地将数据从一个分片迁移到另一个分片，可能带来如下问题，引起业务抖动。
- CPU 消耗过高，迁移过程甚至 CPU 消耗约90%。
- 业务访问抖动，耗时增加。
- 慢日志增加。
- 异常告警增多。

为最大化规避数据迁移引起的业务抖动，可以把 balance 过程和业务高峰期进行错峰。例如设置凌晨0 - 6点低峰期进行 balance 窗口设置，对应命令如下： 
```
use config  
db.settings.update({"_id":"balancer"},{"$set":{"activeWindow":{"start":"00:00","stop":"06:00"}}},true) 
```

### 写多数派优化
零售优码二维码为最核心的数据，为避免极端情况下的数据丢失和数据回归等风险，建议客户端采用 Write Concern 策略 。具体信息，请参见 [MongoDB 官网 Write Concern](https://docs.mongodb.com/manual/reference/write-concern/)。
建议将 Write Concern 的 `w` 选项设置为 majority，并使用 {j: true} 选项来保证写入时 journal 日志持久化之后再返回给客户端确认信息，避免数据回滚现象。然而，可靠性保证的同时，写入性能明显下降。

| 选项          | 描述                                                         | 场景                               |
| :------------ | :----------------------------------------------------------- | :--------------------------------- |
| {w: 0}        | 对客户端的写入不需要发送任何确认信息                         | 不关注数据完整性                   |
| {w: 1}        | 默认的 writeConcern 选项，数据写入到 Primary 就向客户端发送确认信息 | 兼顾性能与一定程度的数据可靠性     |
| {w: majority} | 数据写入到副本集大多数节点后向客户端发送确认信息             | 数据完整性要求比较高、避免数据回滚 |

基于写性能考虑，当业务采用“写大多数”策略时，直接关闭链式复制功能，可解决写链路过长引起的写性能下降的问题。

**链式复制**
假设 A 节点(primary)、B 节点(secondary)、C 节点(secondary)，如果 B 节点从 A 节点同步数据，C 节点从 B 节点同步数据，这样 A->B->C 之间就形成了一个链式的同步结构，如下图所示。
<img src="https://qcloudimg.tencent-cloud.cn/raw/1e7f346c4d614e99ffc32772b626a365.png"  style="zoom:60%;">

**关闭链式复制**
1. MongoDB 分片集群一个分片就是一个副本集，执行如下命令，可确认当前副本集是否支持链式复制。
```
1.    cmgo-xx:SECONDARY> rs.conf().settings.chainingAllowed  
2.    true  
3.    cmgo-xx:SECONDARY> 
```
2. 判断当前副本集节点中是否存在有链式复制情况。您可以查看副本集中每个节点的同步源，如果同步源为 secondary 从节点，则说明副本集中存在链式复制。具体示例，如下所示。
```
1.    cmgo-xx:SECONDARY> rs.status().syncSourceHost  
2.    xx.xx.xx.xx:7021  
3.    cmgo-xx:SECONDARY> 
```
3. 执行如下命令，关闭链式复制功能。
```
1.    cfg = rs.config()  
2.    cfg.settings.chainingAllowed = false
3.    rs.reconfig(cfg) 
```

## 收益总结
腾讯云数据库 MongoDB 作为腾讯智慧零售优码主存储服务，给业务带来了较大收益，主要包括：高性能、快捷的 DDL 操作、低存储成本、超大存储容量等收益，大幅降低了业务存储成本，并提高了业务迭代开发效率。 
